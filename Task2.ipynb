{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as T\n",
    "import pandas as pd\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обрабатываем данные и попутно удаляем оттуда элементы типа NaN  истороковые значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Shanghai_HMT_2010.csv')\n",
    "data = data.dropna() \n",
    "data = data.drop(['cbwd'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проведем нормализацию данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (data - data.mean()) / data.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение давления из data по среднему значение (mediana). Больше - присваивается индекс 1, меньше - индекс 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_median = data['PRES'].median()\n",
    "data['PRES'] = (data['PRES'] > pres_median).astype('int64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проведем сравнение работы метода из sklearn и нашего собственного класса\n",
    "### Начнем с sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error = 0.07789086796720385\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "x = data.drop(['PRES'], axis=1)\n",
    "y = data['PRES']\n",
    "\n",
    "# установим random_state, чтобы результаты эксперимента были воспроизводимы\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "# обучение\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# предсказание\n",
    "predictions_lr = model.predict(x_test)\n",
    "\n",
    "# ошибка\n",
    "error_sklearn = mean_squared_error(predictions_lr, y_test)\n",
    "print(\"mean_squared_error =\", error_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь разберем наш класс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "from MyClass import MyLogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.drop(['PRES'], axis=1)\n",
    "y = data['PRES']\n",
    "\n",
    "# установим random_state, чтобы результаты эксперимента были воспроизводимы\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "type(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tenzor = T.tensor(x_train.to_numpy(), dtype=T.float32).to(device)\n",
    "y_train_tenzor = T.tensor(y_train.to_numpy(), dtype=T.long).to(device)\n",
    "\n",
    "\n",
    "x_test_tenzor = T.tensor(x_test.to_numpy(), dtype=T.float32).to(device)\n",
    "y_test_tenzor = T.tensor(y_test.to_numpy(), dtype=T.long).to(device)\n",
    "\n",
    "num_of_features = x_train_tenzor.size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =    0    loss = 0.2482\n",
      "epoch =    4    loss = 0.1035\n",
      "epoch =    8    loss = 0.0885\n"
     ]
    }
   ],
   "source": [
    "mymodel = MyLogisticRegression(num_of_features)\n",
    "times = 12\n",
    "w, b = mymodel.fit(times, x_train_tenzor, y_train_tenzor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tenzor = T.tensor(x_test.to_numpy(), dtype=T.float32).to(device)\n",
    "predicts = mymodel.predictions(x_test_tenzor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error = 0.07879420790545504\n"
     ]
    }
   ],
   "source": [
    "error = mean_squared_error(predicts, y_test)\n",
    "print(\"mean_squared_error =\", error)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63935a4ebb5f63c50eee506acd6e5a674a9a7ecdbc5bf1518389696c4a80f62e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
